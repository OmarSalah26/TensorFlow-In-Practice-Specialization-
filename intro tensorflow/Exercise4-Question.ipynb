{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import zipfile\n",
    "from os import path, getcwd, chdir\n",
    "\n",
    "# DO NOT CHANGE THE LINE BELOW. If you are developing in a local\n",
    "# environment, then grab happy-or-sad.zip from the Coursera Jupyter Notebook\n",
    "# and place it inside a local folder and edit the path to that location\n",
    "path = f\"{getcwd()}/../tmp2/happy-or-sad.zip\"\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "    \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\" \\\n",
    "    -O \"/tmp/happy-or-sad.zip\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\LEGION/../tmp2/happy-or-sad.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-a0649c14f8d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlocal_zip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mzip_ref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_zip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/tmp2/happy-or-sad'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[0;32m   1205\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1208\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\LEGION/../tmp2/happy-or-sad.zip'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = path\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp2/happy-or-sad')\n",
    "\n",
    "zip_ref.close()\n",
    "# Directory with our training horse pictures\n",
    "train_happy_or_sad_dir = os.path.join('/tmp2/happy-or-sad')\n",
    "train_happy_or_sad_names = os.listdir(train_horse_dir)\n",
    "train_horse_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_happy_sad_model\n",
    "def train_happy_sad_model():\n",
    "    # Please write your code only where you are indicated.\n",
    "    # please do not remove # model fitting inline comments.\n",
    "\n",
    "    DESIRED_ACCURACY = 0.999\n",
    "\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "         # Your Code\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if logs.get('accuracy') >= DESIRED_ACCURACY:\n",
    "                self.model.stop_training = True\n",
    "                print('99% Accuracy achieved')\n",
    "\n",
    "    callbacks = myCallback()\n",
    "        \n",
    "\n",
    "    callbacks = myCallback()\n",
    "    \n",
    "    # This Code Block should Define and Compile the Model. Please assume the images are 150 X 150 in your implementation.\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # Your Code Here\n",
    "\n",
    "        tf.keras.layers.Conv2D(16,(3,3),activation=\"relu\",input_shape=(150,150,3)),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(32,(3,3),activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(32,(3,3),activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512,activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1,activation=\"sigmoid\")  \n",
    "    ])\n",
    "\n",
    "    from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.001),\n",
    "                 metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "    # This code block should create an instance of an ImageDataGenerator called train_datagen \n",
    "    # And a train_generator by calling train_datagen.flow_from_directory\n",
    "\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Please use a target_size of 150 X 150.\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        # Your Code Here\n",
    "        directory= 'tmp2/happy-or-sad',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=10,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    # Expected output: 'Found 80 images belonging to 2 classes'\n",
    "\n",
    "    # This code block should call model.fit_generator and train for\n",
    "    # a number of epochs.\n",
    "    # model fitting\n",
    "    history = model.fit_generator(\n",
    "          # Your Code Here\n",
    "        train_generator,\n",
    "        steps_per_epoch=2,\n",
    "        epochs=15,\n",
    "        verbose=1,\n",
    "        callbacks=[callbacks]\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_happy_sad_model\n",
    "def train_happy_sad_model():\n",
    "    # Please write your code only where you are indicated.\n",
    "    # please do not remove # model fitting inline comments.\n",
    "    \n",
    "    DESIRED_ACCURACY = 0.999\n",
    "\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "            if(logs.get('acc')>DESIRED_ACCURACY):\n",
    "            \n",
    "                print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "                \n",
    "         # Your Code\n",
    "\n",
    "    callbacks = myCallback()\n",
    "    \n",
    "    # This Code Block should Define and Compile the Model. Please assume the images are 150 X 150 in your implementation.\n",
    "    model = tf.keras.models.Sequential([\n",
    "\n",
    "        tf.keras.layers.Conv2D(16,(3,3),activation=\"relu\",input_shape=(150,150,3)),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(32,(3,3),activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(32,(3,3),activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512,activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
    " \n",
    "    ])\n",
    "\n",
    "    from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "    model.compile(optimizer=RMSprop(lr=0.001),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "        \n",
    "\n",
    "    # This code block should create an instance of an ImageDataGenerator called train_datagen \n",
    "    # And a train_generator by calling train_datagen.flow_from_directory\n",
    "\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "    train_datagen =ImageDataGenerator(rescale=1./255) \n",
    "\n",
    "    # Please use a target_size of 150 X 150.\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        '/tmp2/happy-or-sad',  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=10,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary'\n",
    "        \n",
    "    )\n",
    "    # Expected output: 'Found 80 images belonging to 2 classes'\n",
    "\n",
    "    # This code block should call model.fit_generator and train for\n",
    "    # a number of epochs.\n",
    "    # model fitting\n",
    "    history = model.fit_generator(      \n",
    "          train_generator,\n",
    "        \n",
    "          epochs=15,\n",
    "          verbose=1,\n",
    "          callbacks=[callbacks]\n",
    "          # Your Code Here\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/tmp2/happy-or-sad'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a7dc121ed15a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# The Expected output: \"Reached 99.9% accuracy so cancelling training!\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_happy_sad_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-06df93535967>\u001b[0m in \u001b[0;36mtrain_happy_sad_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;31m# Since we use binary_crossentropy loss, we need binary labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    541\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m         )\n\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/tmp2/happy-or-sad'"
     ]
    }
   ],
   "source": [
    "# The Expected output: \"Reached 99.9% accuracy so cancelling training!\"\"\n",
    "train_happy_sad_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
